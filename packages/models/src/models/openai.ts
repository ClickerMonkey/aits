/**
 * Generated model data
 *
 * This file is auto-generated by the scraper scripts.
 * Do not edit manually - your changes will be overwritten.
 *
 * To regenerate, run: npm run scrape
 */

import type { ModelInfo } from '@aits/ai';

export const openaiModels: ModelInfo[] = [{
  id: 'gpt-4-0613',
  provider: 'openai',
  name: 'gpt-4-0613',
  contextWindow: 8192,
  maxOutputTokens: 8192,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 30,
      output: 60
    }
  },
  metadata: {
    knowledgeCutoff: "dec 01, 2023",
    performance: "average",
    speed: "medium"
  }
}, {
  id: 'gpt-4',
  provider: 'openai',
  name: 'gpt-4',
  contextWindow: 8192,
  maxOutputTokens: 8192,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 30,
      output: 60
    }
  },
  metadata: {
    knowledgeCutoff: "dec 01, 2023",
    performance: "average",
    speed: "medium"
  }
}, {
  id: 'gpt-3.5-turbo',
  provider: 'openai',
  name: 'gpt-3.5-turbo',
  contextWindow: 16385,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 0.5,
      output: 1.5
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "slow"
  }
}, {
  id: 'gpt-realtime-mini',
  provider: 'openai',
  name: 'gpt-realtime-mini',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'flagship',
  capabilities: new Set(['vision', 'hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4,
      cached: 0.06
    },
    audio: {
      input: 10,
      output: 20
    },
    image: {
      input: 0.8
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "higher",
    speed: "very fast"
  }
}, {
  id: 'gpt-realtime-mini-2025-10-06',
  provider: 'openai',
  name: 'gpt-realtime-mini-2025-10-06',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'flagship',
  capabilities: new Set(['vision', 'hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4,
      cached: 0.06
    },
    audio: {
      input: 10,
      output: 20
    },
    image: {
      input: 0.8
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "higher",
    speed: "very fast"
  }
}, {
  id: 'sora-2',
  provider: 'openai',
  name: 'sora-2',
  contextWindow: 0,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'audio']),
  pricing: {},
  metadata: {
    intelligence: "higher",
    speed: "slow"
  }
}, {
  id: 'sora-2-pro',
  provider: 'openai',
  name: 'sora-2-pro',
  contextWindow: 0,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'audio']),
  pricing: {},
  metadata: {
    intelligence: "highest",
    speed: "slow"
  }
}, {
  id: 'davinci-002',
  provider: 'openai',
  name: 'davinci-002',
  contextWindow: 0,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  pricing: {
    text: {
      input: 2,
      output: 2
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "medium"
  }
}, {
  id: 'babbage-002',
  provider: 'openai',
  name: 'babbage-002',
  contextWindow: 0,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  pricing: {
    text: {
      input: 0.4,
      output: 0.4
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "medium"
  }
}, {
  id: 'gpt-3.5-turbo-instruct',
  provider: 'openai',
  name: 'gpt-3.5-turbo-instruct',
  contextWindow: 4096,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 1.5,
      output: 2
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "slow"
  }
}, {
  id: 'gpt-3.5-turbo-instruct-0914',
  provider: 'openai',
  name: 'gpt-3.5-turbo-instruct-0914',
  contextWindow: 4096,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 1.5,
      output: 2
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "slow"
  }
}, {
  id: 'dall-e-3',
  provider: 'openai',
  name: 'dall-e-3',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['image', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    image: {
      output: [
        {
          quality: "standard",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.04
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.08
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.08
            }
          ]
        },
        {
          quality: "hd",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.08
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.12
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.12
            }
          ]
        }
      ]
    }
  },
  metadata: {
    intelligence: "high",
    speed: "slow"
  }
}, {
  id: 'dall-e-2',
  provider: 'openai',
  name: 'dall-e-2',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['image', 'chat']),
  supportedParameters: new Set(['imageStyle', 'imageMultiple']),
  pricing: {
    image: {
      output: [
        {
          quality: "standard",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.016
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.018
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.02
            }
          ]
        }
      ]
    }
  },
  metadata: {
    intelligence: "low",
    speed: "slow"
  }
}, {
  id: 'gpt-3.5-turbo-1106',
  provider: 'openai',
  name: 'gpt-3.5-turbo-1106',
  contextWindow: 16385,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 1,
      output: 2
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "slow"
  }
}, {
  id: 'tts-1-hd',
  provider: 'openai',
  name: 'tts-1-hd',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['audio', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    audio: {
      output: 30
    }
  },
  metadata: {
    intelligence: "high",
    speed: "medium"
  }
}, {
  id: 'tts-1-1106',
  provider: 'openai',
  name: 'tts-1-1106',
  contextWindow: 0,
  tier: 'efficient',
  capabilities: new Set(['audio', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    audio: {
      output: 15
    }
  },
  metadata: {
    intelligence: "average",
    speed: "fast"
  }
}, {
  id: 'tts-1-hd-1106',
  provider: 'openai',
  name: 'tts-1-hd-1106',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['audio', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    audio: {
      output: 30
    }
  },
  metadata: {
    intelligence: "high",
    speed: "medium"
  }
}, {
  id: 'text-embedding-3-small',
  provider: 'openai',
  name: 'text-embedding-3-small',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['embedding', 'chat']),
  supportedParameters: new Set(['embeddingDimensions']),
  pricing: {
    embeddings: {
      cost: 0.02
    }
  },
  metadata: {
    intelligence: "average",
    speed: "medium"
  }
}, {
  id: 'text-embedding-3-large',
  provider: 'openai',
  name: 'text-embedding-3-large',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['embedding', 'chat']),
  supportedParameters: new Set(['embeddingDimensions']),
  pricing: {
    embeddings: {
      cost: 0.13
    }
  },
  metadata: {
    intelligence: "high",
    speed: "slow"
  }
}, {
  id: 'gpt-4-turbo-preview',
  provider: 'openai',
  name: 'gpt-4-turbo-preview',
  contextWindow: 128000,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 10,
      output: 30
    }
  },
  metadata: {
    knowledgeCutoff: "dec 01, 2023",
    performance: "average",
    speed: "medium"
  }
}, {
  id: 'gpt-3.5-turbo-0125',
  provider: 'openai',
  name: 'gpt-3.5-turbo-0125',
  contextWindow: 16385,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 0.5,
      output: 1.5
    }
  },
  metadata: {
    knowledgeCutoff: "sep 01, 2021",
    performance: "low",
    speed: "slow"
  }
}, {
  id: 'gpt-4-turbo',
  provider: 'openai',
  name: 'gpt-4-turbo',
  contextWindow: 128000,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 10,
      output: 30
    }
  },
  metadata: {
    knowledgeCutoff: "dec 01, 2023",
    performance: "average",
    speed: "medium"
  }
}, {
  id: 'gpt-4-turbo-2024-04-09',
  provider: 'openai',
  name: 'gpt-4-turbo-2024-04-09',
  contextWindow: 128000,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 10,
      output: 30
    }
  },
  metadata: {
    knowledgeCutoff: "dec 01, 2023",
    performance: "average",
    speed: "medium"
  }
}, {
  id: 'gpt-4o',
  provider: 'openai',
  name: 'gpt-4o',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10,
      cached: 1.25
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-2024-05-13',
  provider: 'openai',
  name: 'gpt-4o-2024-05-13',
  contextWindow: 128000,
  maxOutputTokens: 4096,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 5,
      output: 15
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-mini-2024-07-18',
  provider: 'openai',
  name: 'gpt-4o-mini-2024-07-18',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6,
      cached: 0.075
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "average",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-mini',
  provider: 'openai',
  name: 'gpt-4o-mini',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6,
      cached: 0.075
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "average",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-2024-08-06',
  provider: 'openai',
  name: 'gpt-4o-2024-08-06',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10,
      cached: 1.25
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'chatgpt-4o-latest',
  provider: 'openai',
  name: 'chatgpt-4o-latest',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'stop']),
  pricing: {
    text: {
      input: 5,
      output: 15
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'o1-mini-2024-09-12',
  provider: 'openai',
  name: 'o1-mini-2024-09-12',
  contextWindow: 128000,
  maxOutputTokens: 65536,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'stop']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.55
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "high",
    speed: "slow"
  }
}, {
  id: 'o1-mini',
  provider: 'openai',
  name: 'o1-mini',
  contextWindow: 128000,
  maxOutputTokens: 65536,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'stop']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.55
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "high",
    speed: "slow"
  }
}, {
  id: 'gpt-4o-realtime-preview-2024-10-01',
  provider: 'openai',
  name: 'gpt-4o-realtime-preview-2024-10-01',
  contextWindow: 16000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 5,
      output: 20,
      cached: 2.5
    },
    audio: {
      input: 100,
      output: 200
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "average",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-audio-preview-2024-10-01',
  provider: 'openai',
  name: 'gpt-4o-audio-preview-2024-10-01',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 100,
      output: 200
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-audio-preview',
  provider: 'openai',
  name: 'gpt-4o-audio-preview',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-realtime-preview',
  provider: 'openai',
  name: 'gpt-4o-realtime-preview',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 5,
      output: 20,
      cached: 2.5
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "high",
    speed: "fast"
  }
}, {
  id: 'omni-moderation-latest',
  provider: 'openai',
  name: 'omni-moderation-latest',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision']),
  pricing: {},
  metadata: {
    intelligence: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-realtime-preview-2024-12-17',
  provider: 'openai',
  name: 'gpt-4o-realtime-preview-2024-12-17',
  contextWindow: 16000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 5,
      output: 20,
      cached: 2.5
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-audio-preview-2024-12-17',
  provider: 'openai',
  name: 'gpt-4o-audio-preview-2024-12-17',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-mini-realtime-preview-2024-12-17',
  provider: 'openai',
  name: 'gpt-4o-mini-realtime-preview-2024-12-17',
  contextWindow: 16000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4,
      cached: 0.3
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-4o-mini-audio-preview-2024-12-17',
  provider: 'openai',
  name: 'gpt-4o-mini-audio-preview-2024-12-17',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "average",
    speed: "fast"
  }
}, {
  id: 'o1-2024-12-17',
  provider: 'openai',
  name: 'o1-2024-12-17',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 15,
      output: 60,
      cached: 7.5
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "slow"
  }
}, {
  id: 'o1',
  provider: 'openai',
  name: 'o1',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 15,
      output: 60,
      cached: 7.5
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "slow"
  }
}, {
  id: 'gpt-4o-mini-realtime-preview',
  provider: 'openai',
  name: 'gpt-4o-mini-realtime-preview',
  contextWindow: 16000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4,
      cached: 0.3
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-4o-mini-audio-preview',
  provider: 'openai',
  name: 'gpt-4o-mini-audio-preview',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "average",
    speed: "fast"
  }
}, {
  id: 'o3-mini',
  provider: 'openai',
  name: 'o3-mini',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.55
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'o3-mini-2025-01-31',
  provider: 'openai',
  name: 'o3-mini-2025-01-31',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.55
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-2024-11-20',
  provider: 'openai',
  name: 'gpt-4o-2024-11-20',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10,
      cached: 1.25
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-search-preview-2025-03-11',
  provider: 'openai',
  name: 'gpt-4o-search-preview-2025-03-11',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-search-preview',
  provider: 'openai',
  name: 'gpt-4o-search-preview',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'streaming', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-mini-search-preview-2025-03-11',
  provider: 'openai',
  name: 'gpt-4o-mini-search-preview-2025-03-11',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['chat', 'streaming', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "average",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-mini-search-preview',
  provider: 'openai',
  name: 'gpt-4o-mini-search-preview',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'efficient',
  capabilities: new Set(['chat', 'streaming', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.15,
      output: 0.6
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "average",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-transcribe',
  provider: 'openai',
  name: 'gpt-4o-transcribe',
  contextWindow: 16000,
  maxOutputTokens: 2000,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'chat']),
  supportedParameters: new Set(['transcribePrompt', 'transcribeStream']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 6
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    intelligence: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-4o-mini-transcribe',
  provider: 'openai',
  name: 'gpt-4o-mini-transcribe',
  contextWindow: 16000,
  maxOutputTokens: 2000,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'chat']),
  supportedParameters: new Set(['transcribePrompt', 'transcribeStream']),
  pricing: {
    text: {
      input: 1.25,
      output: 5
    },
    audio: {
      input: 3
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    intelligence: "high",
    speed: "fast"
  }
}, {
  id: 'o1-pro-2025-03-19',
  provider: 'openai',
  name: 'o1-pro-2025-03-19',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 150,
      output: 600
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "slow"
  }
}, {
  id: 'o1-pro',
  provider: 'openai',
  name: 'o1-pro',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 150,
      output: 600
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    reasoning: "higher",
    speed: "slow"
  }
}, {
  id: 'gpt-4o-mini-tts',
  provider: 'openai',
  name: 'gpt-4o-mini-tts',
  contextWindow: 0,
  tier: 'flagship',
  capabilities: new Set(['audio', 'chat']),
  supportedParameters: new Set(['speechInstructions']),
  pricing: {
    text: {
      input: 0.6
    },
    audio: {
      output: 12
    }
  },
  metadata: {
    intelligence: "higher",
    speed: "fast"
  }
}, {
  id: 'o3-2025-04-16',
  provider: 'openai',
  name: 'o3-2025-04-16',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1,
      output: 4,
      cached: 0.25
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'o4-mini-2025-04-16',
  provider: 'openai',
  name: 'o4-mini-2025-04-16',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.275
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'o3',
  provider: 'openai',
  name: 'o3',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1,
      output: 4,
      cached: 0.25
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'o4-mini',
  provider: 'openai',
  name: 'o4-mini',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput']),
  pricing: {
    text: {
      input: 1.1,
      output: 4.4,
      cached: 0.275
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-4.1-2025-04-14',
  provider: 'openai',
  name: 'gpt-4.1-2025-04-14',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 2,
      output: 8,
      cached: 0.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-4.1',
  provider: 'openai',
  name: 'gpt-4.1',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 2,
      output: 8,
      cached: 0.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-4.1-mini-2025-04-14',
  provider: 'openai',
  name: 'gpt-4.1-mini-2025-04-14',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.4,
      output: 1.6,
      cached: 0.1
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-4.1-mini',
  provider: 'openai',
  name: 'gpt-4.1-mini',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.4,
      output: 1.6,
      cached: 0.1
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-4.1-nano-2025-04-14',
  provider: 'openai',
  name: 'gpt-4.1-nano-2025-04-14',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.1,
      output: 0.4,
      cached: 0.025
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-4.1-nano',
  provider: 'openai',
  name: 'gpt-4.1-nano',
  contextWindow: 1047576,
  maxOutputTokens: 32768,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.1,
      output: 0.4,
      cached: 0.025
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    performance: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-image-1',
  provider: 'openai',
  name: 'gpt-image-1',
  contextWindow: 0,
  tier: 'flagship',
  capabilities: new Set(['vision', 'image', 'chat']),
  supportedParameters: new Set(['imageStyle', 'imageMultiple', 'imageBackground', 'imageStream', 'imageFormat']),
  pricing: {
    text: {
      input: 5,
      cached: 1.25
    },
    image: {
      input: 10,
      output: [
        {
          quality: "low",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.011
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.016
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.016
            }
          ]
        },
        {
          quality: "medium",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.042
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.063
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.063
            }
          ]
        },
        {
          quality: "high",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.167
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.25
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.25
            }
          ]
        }
      ]
    }
  },
  metadata: {
    intelligence: "higher",
    speed: "slow"
  }
}, {
  id: 'codex-mini-latest',
  provider: 'openai',
  name: 'codex-mini-latest',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 1.5,
      output: 6,
      cached: 0.375
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    intelligence: "higher",
    speed: "medium"
  }
}, {
  id: 'o3-pro',
  provider: 'openai',
  name: 'o3-pro',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 20,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'gpt-4o-realtime-preview-2025-06-03',
  provider: 'openai',
  name: 'gpt-4o-realtime-preview-2025-06-03',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'efficient',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 5,
      output: 20,
      cached: 2.5
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-4o-audio-preview-2025-06-03',
  provider: 'openai',
  name: 'gpt-4o-audio-preview-2025-06-03',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['hearing', 'audio', 'chat', 'streaming', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 40,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'o3-pro-2025-06-10',
  provider: 'openai',
  name: 'o3-pro-2025-06-10',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 20,
      output: 80
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'o4-mini-deep-research',
  provider: 'openai',
  name: 'o4-mini-deep-research',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'reasoning']),
  pricing: {
    text: {
      input: 2,
      output: 8,
      cached: 0.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'o3-deep-research',
  provider: 'openai',
  name: 'o3-deep-research',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'reasoning']),
  pricing: {
    text: {
      input: 10,
      output: 40,
      cached: 2.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'gpt-4o-transcribe-diarize',
  provider: 'openai',
  name: 'gpt-4o-transcribe-diarize',
  contextWindow: 16000,
  maxOutputTokens: 2000,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'chat']),
  supportedParameters: new Set(['transcribeStream']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 6
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    intelligence: "higher",
    speed: "medium"
  }
}, {
  id: 'o3-deep-research-2025-06-26',
  provider: 'openai',
  name: 'o3-deep-research-2025-06-26',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'reasoning']),
  pricing: {
    text: {
      input: 10,
      output: 40,
      cached: 2.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'o4-mini-deep-research-2025-06-26',
  provider: 'openai',
  name: 'o4-mini-deep-research-2025-06-26',
  contextWindow: 200000,
  maxOutputTokens: 100000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'reasoning']),
  pricing: {
    text: {
      input: 2,
      output: 8,
      cached: 0.5
    }
  },
  metadata: {
    knowledgeCutoff: "jun 01, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-5-chat-latest',
  provider: 'openai',
  name: 'gpt-5-chat-latest',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'legacy',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 1.25,
      output: 10,
      cached: 0.125
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    performance: "high",
    speed: "medium"
  }
}, {
  id: 'gpt-5-2025-08-07',
  provider: 'openai',
  name: 'gpt-5-2025-08-07',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 1.25,
      output: 10,
      cached: 0.125
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-5',
  provider: 'openai',
  name: 'gpt-5',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 1.25,
      output: 10,
      cached: 0.125
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-5-mini-2025-08-07',
  provider: 'openai',
  name: 'gpt-5-mini-2025-08-07',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.25,
      output: 2,
      cached: 0.025
    }
  },
  metadata: {
    knowledgeCutoff: "may 31, 2024",
    reasoning: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-5-mini',
  provider: 'openai',
  name: 'gpt-5-mini',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop']),
  pricing: {
    text: {
      input: 0.25,
      output: 2,
      cached: 0.025
    }
  },
  metadata: {
    knowledgeCutoff: "may 31, 2024",
    reasoning: "high",
    speed: "fast"
  }
}, {
  id: 'gpt-5-nano-2025-08-07',
  provider: 'openai',
  name: 'gpt-5-nano-2025-08-07',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 0.05,
      output: 0.4,
      cached: 0.005
    }
  },
  metadata: {
    knowledgeCutoff: "may 31, 2024",
    reasoning: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-5-nano',
  provider: 'openai',
  name: 'gpt-5-nano',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'efficient',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'reason', 'tools', 'toolChoice', 'responseFormat', 'structuredOutput', 'stop', 'imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 0.05,
      output: 0.4,
      cached: 0.005
    }
  },
  metadata: {
    knowledgeCutoff: "may 31, 2024",
    reasoning: "average",
    speed: "very fast"
  }
}, {
  id: 'gpt-audio-2025-08-28',
  provider: 'openai',
  name: 'gpt-audio-2025-08-28',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 32,
      output: 64
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-realtime',
  provider: 'openai',
  name: 'gpt-realtime',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'flagship',
  capabilities: new Set(['vision', 'hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 4,
      output: 16,
      cached: 0.5
    },
    audio: {
      input: 32,
      output: 64
    },
    image: {
      input: 5
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "highest",
    speed: "fast"
  }
}, {
  id: 'gpt-realtime-2025-08-28',
  provider: 'openai',
  name: 'gpt-realtime-2025-08-28',
  contextWindow: 32000,
  maxOutputTokens: 4096,
  tier: 'flagship',
  capabilities: new Set(['vision', 'hearing', 'audio', 'chat', 'tools']),
  pricing: {
    text: {
      input: 4,
      output: 16,
      cached: 0.5
    },
    audio: {
      input: 32,
      output: 64
    },
    image: {
      input: 5
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    intelligence: "highest",
    speed: "fast"
  }
}, {
  id: 'gpt-audio',
  provider: 'openai',
  name: 'gpt-audio',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 2.5,
      output: 10
    },
    audio: {
      input: 32,
      output: 64
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-5-codex',
  provider: 'openai',
  name: 'gpt-5-codex',
  contextWindow: 400000,
  maxOutputTokens: 128000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'streaming', 'tools', 'structured', 'json', 'reasoning']),
  pricing: {
    text: {
      input: 1.25,
      output: 10,
      cached: 0.125
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    reasoning: "higher",
    speed: "medium"
  }
}, {
  id: 'gpt-image-1-mini',
  provider: 'openai',
  name: 'gpt-image-1-mini',
  contextWindow: 0,
  tier: 'flagship',
  capabilities: new Set(['vision', 'image', 'chat']),
  supportedParameters: new Set(['imageStyle', 'imageMultiple', 'imageBackground', 'imageStream', 'imageFormat']),
  pricing: {
    text: {
      input: 2,
      cached: 0.2
    },
    image: {
      input: 2.5,
      output: [
        {
          quality: "low",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.005
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.006
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.006
            }
          ]
        },
        {
          quality: "medium",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.011
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.015
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.015
            }
          ]
        },
        {
          quality: "high",
          sizes: [
            {
              width: 1024,
              height: 1024,
              cost: 0.036
            },
            {
              width: 1024,
              height: 1536,
              cost: 0.052
            },
            {
              width: 1536,
              height: 1024,
              cost: 0.052
            }
          ]
        }
      ]
    }
  },
  metadata: {
    intelligence: "higher",
    speed: "slow"
  }
}, {
  id: 'gpt-5-pro-2025-10-06',
  provider: 'openai',
  name: 'gpt-5-pro-2025-10-06',
  contextWindow: 400000,
  maxOutputTokens: 272000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 15,
      output: 120
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'gpt-5-pro',
  provider: 'openai',
  name: 'gpt-5-pro',
  contextWindow: 400000,
  maxOutputTokens: 272000,
  tier: 'flagship',
  capabilities: new Set(['chat', 'vision', 'tools', 'structured', 'json', 'reasoning']),
  supportedParameters: new Set(['imageStyle', 'imageMultiple']),
  pricing: {
    text: {
      input: 15,
      output: 120
    }
  },
  metadata: {
    knowledgeCutoff: "sep 30, 2024",
    reasoning: "highest",
    speed: "slow"
  }
}, {
  id: 'gpt-audio-mini',
  provider: 'openai',
  name: 'gpt-audio-mini',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "higher",
    speed: "very fast"
  }
}, {
  id: 'gpt-audio-mini-2025-10-06',
  provider: 'openai',
  name: 'gpt-audio-mini-2025-10-06',
  contextWindow: 128000,
  maxOutputTokens: 16384,
  tier: 'flagship',
  capabilities: new Set(['hearing', 'audio', 'chat', 'tools']),
  supportedParameters: new Set(['maxTokens', 'temperature', 'topP', 'frequencyPenalty', 'presencePenalty', 'logitBias', 'logProbabilities', 'tools', 'toolChoice', 'stop']),
  pricing: {
    text: {
      input: 0.6,
      output: 2.4
    },
    audio: {
      input: 10,
      output: 20
    }
  },
  metadata: {
    knowledgeCutoff: "oct 01, 2023",
    performance: "higher",
    speed: "very fast"
  }
}, {
  id: 'tts-1',
  provider: 'openai',
  name: 'tts-1',
  contextWindow: 0,
  tier: 'efficient',
  capabilities: new Set(['audio', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    audio: {
      output: 15
    }
  },
  metadata: {
    intelligence: "average",
    speed: "fast"
  }
}, {
  id: 'whisper-1',
  provider: 'openai',
  name: 'whisper-1',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['hearing']),
  supportedParameters: new Set(['transcribePrompt']),
  pricing: {
    audio: {
      input: 0.006
    }
  },
  metadata: {
    intelligence: "average",
    speed: "medium"
  }
}, {
  id: 'text-embedding-ada-002',
  provider: 'openai',
  name: 'text-embedding-ada-002',
  contextWindow: 0,
  tier: 'legacy',
  capabilities: new Set(['embedding', 'chat']),
  supportedParameters: new Set([]),
  pricing: {
    embeddings: {
      cost: 0.1
    }
  },
  metadata: {
    intelligence: "low",
    speed: "slow"
  }
}];
